{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import time\n",
    "import pymongo\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "from pymongo.errors import WriteError, DuplicateKeyError\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import os\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "testDB = client.abaco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example request\n",
    "#'?search=car&exactsearch=DEV-DEVELOP&search=dog&&skip=0&limit=10'\n",
    "\n",
    "# Mongo aggregation comparison expression operators to implement:\n",
    "# $eq, $gt, %gte, $lt, $lte, $ne, $in, $nin\n",
    "\n",
    "def get(search_type, args):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    #args = dict(args.lists())    \n",
    "    search_type = search_type.lower()\n",
    "    queried_store, security, project = get_db_specific_sections(search_type)\n",
    "    search, query, paging = arg_parser(args, tenant)\n",
    "    pipeline = search + query + security + paging #project\n",
    "    pprint.pprint(list(queried_store.aggregate(pipeline))[2:3])\n",
    "    \n",
    "        \n",
    "def get_db_specific_sections(search_type):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    store_dict = {'executions': testDB['3'],\n",
    "                  'workers': testDB['6'],\n",
    "                  'actors': testDB['5'],\n",
    "                  'logs': testDB['1']}\n",
    "    try:\n",
    "        queried_store = store_dict[search_type]\n",
    "    except KeyError:\n",
    "        raise KeyError(f'Inputted search_type is invalid, must be one of {list(store_dict.keys())}.')\n",
    "    \n",
    "    localField = 'actor_id'\n",
    "    if search_type =='actors':\n",
    "        localField = '_id'\n",
    "    \n",
    "    security = [{'$match': {'tenant': tenant}},\n",
    "                {'$lookup':\n",
    "                    {'from' : '2',\n",
    "                     'localField' : localField,\n",
    "                     'foreignField' : '_id',\n",
    "                     'as' : 'permissions'}},\n",
    "                {'$unwind': '$permissions'},\n",
    "                {'$match': {'permissions.' + curr_user: {'$exists': True}}}]\n",
    "    \n",
    "    if search_type == 'executions':\n",
    "        project = [{'project': {'ijaiosjdioasjd'}}]\n",
    "        \n",
    "    elif search_type == 'workers':\n",
    "        project = [{'project': {'ijaiosjdioasjd'}}]\n",
    "        \n",
    "    elif search_type == 'actors':\n",
    "        project = [{'project': {'ijaiosjdioasjd'}}]\n",
    "        \n",
    "    elif search_type == 'logs':\n",
    "        project = [{'project': {'ijaiosjdioasjd'}}]\n",
    "        \n",
    "    return queried_store, security, project\n",
    "\n",
    "def arg_parser(args, tenant):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    query = []\n",
    "    search = f'\"{tenant}\"'\n",
    "    paging = []\n",
    "    skip_amo = None\n",
    "    limit_amo = None\n",
    "    \n",
    "    for key, val in args.items():\n",
    "        if key == \"search\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = ' '.join(val)\n",
    "                search = search + f' {joined_val}'\n",
    "            else:\n",
    "                search = search + f' {val}'\n",
    "        elif key == \"exactsearch\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = '\" \"'.join(val)\n",
    "                search = search + f' \"{joined_val}\"'\n",
    "            else:\n",
    "                search = search + f' \"{val}\"'\n",
    "        elif key == \"skip\":\n",
    "            if isinstance(val, list):\n",
    "                raise KeyError('Inputted \"skip\" paramater is invalid, parameter can only be specified once')\n",
    "            else:\n",
    "                skip_amo = int(val)\n",
    "                paging = paging + [{'$skip': skip_amo}]\n",
    "        elif key == \"limit\":\n",
    "            if isinstance(val, list):\n",
    "                raise KeyError('Inputted \"limit\" paramater is invalid, parameter can only be specified once')\n",
    "            else:\n",
    "                limit_amo = int(val)\n",
    "                paging = paging + [{'$limit': limit_amo}]\n",
    "        else:\n",
    "            used_oper = False\n",
    "            for oper in ['.$eq', '.$gt', '.$gte', '.$lt', '.$lte', '.$ne']:\n",
    "                if oper in key:\n",
    "                    key = key.split(oper)[0]\n",
    "                    oper = oper[1:]\n",
    "                    query += [{'$match': {key: {oper: val}}}]\n",
    "                    used_oper = True\n",
    "                    break\n",
    "            if not used_oper:\n",
    "                query += [{'$match': {key: val}}]\n",
    "\n",
    "    search = [{'$match': {'$text': {'$search': search}}},\n",
    "              {'$sort': {'score': {'$meta': 'textScore'}}}]    \n",
    "\n",
    "    return search, query, paging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz \n",
    "AUS = pytz.timezone(\"America/Chicago\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broad_ISO_to_datetime(dt_str):\n",
    "    \"\"\"\n",
    "    Parses a broadly conforming ISO 8601 string.\n",
    "    \"\"\"\n",
    "    dt_str = dt_str.replace('Z', '')\n",
    "    dt_tz_ready = dt_str[:19] + dt_str[19:].replace(':', '')\n",
    "    datetime_strs = ['%Y-%m-%dT%H:%M:%S.%f%z',\n",
    "                     '%Y-%m-%dT%H:%M:%S.%f',\n",
    "                     '%Y-%m-%dT%H:%M:%S%z',\n",
    "                     '%Y-%m-%dT%H:%M:%S',\n",
    "                     '%Y-%m-%dT%H:%M%z',\n",
    "                     '%Y-%m-%dT%H:%M',\n",
    "                     '%Y-%m-%dT%H%z',\n",
    "                     '%Y-%m-%dT%H',\n",
    "                     '%Y-%m-%dT%z',\n",
    "                     '%Y-%m-%dT',\n",
    "                     '%Y-%m-%d%z',\n",
    "                     '%Y-%m-%d',\n",
    "                     '%Y-%m%z',\n",
    "                     '%Y-%m',\n",
    "                     '%Y%z',\n",
    "                     '%Y']\n",
    "    # Try each parse for each datetime str\n",
    "    for datetime_try in datetime_strs:\n",
    "        # Changing the datetime string to check depending on what we're\n",
    "        # attempted to parse with datetime.datetime.strptime()\n",
    "        if datetime_try == '%Y-%m-%dT%H:%M%z':\n",
    "            dt_tz_ready = dt_str[:16] + dt_str[16:].replace(':', '')\n",
    "        elif datetime_try ==  '%Y-%m-%dT%H%z':\n",
    "            dt_tz_ready = dt_str[:13] + dt_str[13:].replace(':', '')\n",
    "        elif datetime_try == '%Y-%m-%dT%':\n",
    "            dt_tz_ready = dt_str.replace(':', '')\n",
    "        try:\n",
    "            dt = datetime.datetime.strptime(dt_tz_ready, datetime_try)\n",
    "            return dt\n",
    "        except:\n",
    "            pass\n",
    "    # If no parse was successful, error!\n",
    "    raise ValueError(\"Inputted datetime was in an incorrect format.\"\\\n",
    "                     \" Please refer to docs and follow ISO 8601 formatting.\"\\\n",
    "                     \" e.g. '2020-05-01T14:45:41.591Z'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broad_ISO_to_datetime(dt_str):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # There are dz_tz_ready variables to get rid of any colons in timezone information\n",
    "    # being given in the ISO 8601 format. \n",
    "    dt_str = dt_str.replace('Z', '')\n",
    "    try:\n",
    "        dt_tz_ready = dt_str[:19] + dt_str[19:].replace(':', '')\n",
    "        dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "        except ValueError:\n",
    "            try:\n",
    "                dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%H:%M:%S\")\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        dt_tz_ready = dt_str[:16] + dt_str[16:].replace(':', '')\n",
    "                        dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%H:%M%z\")\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%H:%M\")\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                dt_tz_ready = dt_str[:13] + dt_str[13:].replace(':', '')\n",
    "                                dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%H%z\")\n",
    "                            except:\n",
    "                                try:\n",
    "                                    dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%H\")\n",
    "                                except ValueError:\n",
    "                                    try:\n",
    "                                        dt_tz_ready = dt_str.replace(':', '')\n",
    "                                        dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT%z\") \n",
    "                                    except ValueError:\n",
    "                                        try:\n",
    "                                            dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%dT\")\n",
    "                                        except ValueError:\n",
    "                                            try:\n",
    "                                                dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%d%z\")\n",
    "                                            except ValueError:\n",
    "                                                try:\n",
    "                                                    dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m-%d\")\n",
    "                                                except ValueError:\n",
    "                                                    try:\n",
    "                                                        dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m%z\")\n",
    "                                                    except ValueError:\n",
    "                                                        try:\n",
    "                                                            dt = datetime.datetime.strptime(dt_tz_ready, \"%Y-%m\")\n",
    "                                                        except ValueError:\n",
    "                                                            try:\n",
    "                                                                dt = datetime.datetime.strptime(dt_tz_ready, \"%Y%z\")\n",
    "                                                            except ValueError:\n",
    "                                                                try:\n",
    "                                                                    dt = datetime.datetime.strptime(dt_tz_ready, \"%Y\")\n",
    "                                                                except ValueError:\n",
    "                                                                    raise ValueError(\"Inputted datetime was in an incorrect format.\",\n",
    "                                                                                     \" Please refer to docs and follow ISO 8601 formatting.\",\n",
    "                                                                                     \" e.g. '2020-05-01T14:45:41.591Z'\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Inputted datetime was in an incorrect format. Please refer to docs and follow ISO 8601 formatting. e.g. '2020-05-01T14:45:41.591Z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1b82de2357e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbroad_ISO_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dsadas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-28703278c6ae>\u001b[0m in \u001b[0;36mbroad_ISO_to_datetime\u001b[0;34m(dt_str)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     raise ValueError(\"Inputted datetime was in an incorrect format.\"\\\n\u001b[0m\u001b[1;32m     37\u001b[0m                      \u001b[0;34m\" Please refer to docs and follow ISO 8601 formatting.\"\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                      \" e.g. '2020-05-01T14:45:41.591Z'\")\n",
      "\u001b[0;31mValueError\u001b[0m: Inputted datetime was in an incorrect format. Please refer to docs and follow ISO 8601 formatting. e.g. '2020-05-01T14:45:41.591Z'"
     ]
    }
   ],
   "source": [
    "broad_ISO_to_datetime('dsadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 5, 5, 18, 1, 2, 668361, tzinfo=datetime.timezone(datetime.timedelta(-1, 68400)))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broad_ISO_to_datetime(datetime.datetime.now(tz=AUS).isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_str = datetime.datetime.now(tz=AUS).isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_to_under(value):\n",
    "    return re.sub(r'(?<!^)(?=[A-Z])', '_', value).lower()\n",
    "\n",
    "def dict_to_under(d):\n",
    "    \"\"\"Convert all keys in a dictionary to camel case.\"\"\"\n",
    "    d2 = {}\n",
    "    for k,v in d.items():\n",
    "        k = k.split(\".\")\n",
    "        k[0] = camel_to_under(k[0])\n",
    "        k = \".\".join(k)\n",
    "        d2[k] = v\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_parser(args):\n",
    "    query = []\n",
    "    search = f'\"DEV-DEVELOP\"'\n",
    "    skip_amo = 0\n",
    "    limit_amo = 10\n",
    "\n",
    "    #case = Config.get('web', 'case')\n",
    "    case = \"camel\"\n",
    "    if case == 'camel':\n",
    "        args = dict_to_under(args)\n",
    "\n",
    "    for key, val in args.items():\n",
    "        if key == \"search\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = ' '.join(val)\n",
    "                search = search + f' {joined_val}'\n",
    "            else:\n",
    "                search = search + f' {val}'\n",
    "        elif key == \"exactsearch\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = '\" \"'.join(val)\n",
    "                search = search + f' \"{joined_val}\"'\n",
    "            else:\n",
    "                search = search + f' \"{val}\"'\n",
    "        elif key == \"skip\" or key == \"limit\":\n",
    "            try:\n",
    "                val = int(val)\n",
    "            except ValueError:\n",
    "                raise ValueError(f'Inputted \"{key}\" paramater must be an int. Received: {val}')\n",
    "            if val < 0:\n",
    "                raise ValueError(f'Inputted \"{key}\" must be positive. Received: {val}')\n",
    "            if key == \"skip\":\n",
    "                skip_amo = val\n",
    "            if key == \"limit\":\n",
    "                limit_amo = val\n",
    "        else:\n",
    "            time_keys = ['start_time', 'message_received_time', 'last_execution_time',\n",
    "                        'last_update_time', 'StartedAt', 'FinishedAt', 'create_time',\n",
    "                        'last_health_check_time']\n",
    "            if val.lower() == 'false':\n",
    "                val = False\n",
    "            elif val.lower() == 'true':\n",
    "                val = True\n",
    "            elif val.lower() == 'none':\n",
    "                val = None\n",
    "            elif any(time_key in key for time_key in time_keys):\n",
    "                if '.between' in key:\n",
    "                    if not ',' in val:\n",
    "                        raise ValueError('Between must have two variables seperated by a comma. Ex. io.between=20,40')\n",
    "                    time1, time2 = val.split(',')\n",
    "                    time1 = broad_ISO_to_datetime(time1)\n",
    "                    time2 = broad_ISO_to_datetime(time2)\n",
    "                    val = [time1, time2]\n",
    "                else:\n",
    "                    val = broad_ISO_to_datetime(val)\n",
    "            else:\n",
    "                try: \n",
    "                    val = float(val)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                except TypeError:\n",
    "                    pass\n",
    "            used_oper = False\n",
    "\n",
    "            oper_aliases = {'.neq': '$ne', '.eq': '$eq', '.lte': '$lte', '.lt': '$lt',\n",
    "                            '.gte': '$gte', '.gt': '$gt', '.nin': '$nin', '.in': '$in'}\n",
    "            for oper_alias, mongo_oper in oper_aliases.items():\n",
    "                if oper_alias in key:\n",
    "                    key = key.split(oper_alias)[0]\n",
    "                    query += [{'$match': {key: {mongo_oper: val}}}]\n",
    "                    used_oper = True\n",
    "                    break\n",
    "\n",
    "            if not used_oper:\n",
    "                if '.between' in key:\n",
    "                    if isinstance(val, list):\n",
    "                        if isinstance(val[0], datetime.datetime) and isinstance(val[1], datetime.datetime):\n",
    "                            key = key.split('.between')[0]\n",
    "                            query += [{'$match': {key: {'$gte': val[0], '$lte': val[1]}}}]\n",
    "                        else:\n",
    "                            raise ValueError(\"The values given to .between should be either float or ISO 8601 datetime.\")\n",
    "                    else:\n",
    "                        if not ',' in val:\n",
    "                            raise ValueError('Between must have two variables seperated by a comma. Ex. io.between=20,40')\n",
    "                        key = key.split('.between')[0]\n",
    "                        val1, val2 = val.split(',')\n",
    "                        try:\n",
    "                            val1 = float(val1)\n",
    "                            val2 = float(val2)\n",
    "                        except ValueError:\n",
    "                            raise ValueError(\"The values given to .between should be either float or ISO 8601 datetime.\")\n",
    "                        query += [{'$match': {key: {'$gte': val1, '$lte': val2}}}]\n",
    "                    \n",
    "                elif '.nlike' in key:\n",
    "                    key = key.split('.nlike')[0]\n",
    "                    query += [{'$match': {key: {'$not': {'$regex': f\"{val}\"}}}}]\n",
    "\n",
    "                elif '.like' in key:\n",
    "                    key = key.split('.like')[0]\n",
    "                    query += [{'$match': {key: {'$regex': f\"{val}\"}}}]\n",
    " \n",
    "                else:\n",
    "                    query += [{'$match': {key: val}}]\n",
    "                \n",
    "    search = [{'$match': {'$text': {'$search': search}}},\n",
    "              {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "    return search, query, skip_amo, limit_amo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenant = 'DEV-DEVELOP'\n",
    "curr_user = 'testuser'\n",
    "# '?search=7KEaNE8lrRw5k&search=KUBS&exactsearch=car&exactsearch=POPS&aid=FORDHmongENRY&aid.$gt=100010010'\n",
    "# args = {'search': ['7KEaNE8lrRw5k', 'KUBS'], 'exactsearch': ['car', 'POPS'], 'aid':'FORDHENRY', 'aid.$gt': '100010010'}\n",
    "\n",
    "# '?search=DEV-DEVELOP&aid=FORDHENRY&aid.$gt=100010010&skip=0&limit=10'\n",
    "# args = {'search': 'DEV-DEVELOP', 'aid':'FORDHENRY', 'aid.$gt': '100010010', 'skip':'0', 'limit':'10'}\n",
    "\n",
    "args = [{'$match': {'cpu' :{'$in': [433607460]}}}]\n",
    "\n",
    "#args = {'search': 'DEV-DEVELOP_jJqjmq57Vjv55'}\n",
    "\n",
    "#args = {'exactsearch': ''}\n",
    "\n",
    "#args = {'search': 'DEV-DEVELOP', 'actor_id': 'DEV-DEVELOP_jJqjmq57Vjv55'}\n",
    "\n",
    "\n",
    "#pipeline = arg_parser(args)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'$match': {'start_time': {'$lt': datetime.datetime(2020, 4, 26, 0, 0)}}}]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', \"'\", 'c', 'a', 'r', \"'\", ',', ' ', \"'\", 'd', 'o', 'g', \"'\", ']']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"['car', 'dog']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'$match': {'executor.nin': ['testuser']}}]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'DEV-DEVELOP_AKxNjP73pqBzw_jjjrG8JDP5emK',\n",
       "  'actor_id': 'DEV-DEVELOP_AKxNjP73pqBzw',\n",
       "  'api_server': 'https://dev.tenants.aloedev.tacc.cloud',\n",
       "  'cpu': 433607460,\n",
       "  'executor': 'testuser',\n",
       "  'exit_code': 0,\n",
       "  'final_state': {'Status': 'exited',\n",
       "   'Running': False,\n",
       "   'Paused': False,\n",
       "   'Restarting': False,\n",
       "   'OOMKilled': False,\n",
       "   'Dead': False,\n",
       "   'Pid': 0,\n",
       "   'ExitCode': 0,\n",
       "   'Error': '',\n",
       "   'StartedAt': datetime.datetime(2020, 4, 29, 19, 18, 26, 557000),\n",
       "   'FinishedAt': datetime.datetime(2020, 4, 29, 19, 18, 28, 560000)},\n",
       "  'id': 'jjjrG8JDP5emK',\n",
       "  'io': 716,\n",
       "  'message_received_time': datetime.datetime(2020, 4, 29, 19, 18, 25, 820000),\n",
       "  'runtime': 2,\n",
       "  'start_time': datetime.datetime(2020, 4, 29, 19, 18, 26, 105000),\n",
       "  'status': 'COMPLETE',\n",
       "  'tenant': 'DEV-DEVELOP',\n",
       "  'worker_id': '4QA8Z6bKKmlJ1'}]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(testDB['3'].aggregate(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$**_text'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do this to create a wildcard index on littttterally everything.\n",
    "testDB['6'].create_index([('$**', pymongo.TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SON([('v', 2), ('key', SON([('_id', 1)])), ('name', '_id_'), ('ns', 'abaco.6')]),\n",
       " SON([('v', 2), ('key', SON([('_fts', 'text'), ('_ftsx', 1)])), ('name', '$**_text'), ('ns', 'abaco.6'), ('weights', SON([('$**', 1)])), ('default_language', 'english'), ('language_override', 'language'), ('textIndexVersion', 3)])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(testDB['6'].list_indexes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = [{'$match': {'runtime': 2}}]\n",
    "list(testDB['3'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex. Update logs fields if actors exists\n",
    "pipeline = [{'$match': {'$text': {'$search': search}}},\n",
    "            {'$sort': {'score': {'$meta': 'textScore'}}},\n",
    "            {'$match': {'tenant': tenant}},\n",
    "            {'$lookup':\n",
    "                {'from' : '2',\n",
    "                 'localField' : 'actor_id',\n",
    "                 'foreignField' : '_ifd',\n",
    "                 'as' : 'permissions'}},\n",
    "            {'$unwind': '$permissions'},\n",
    "            {'$match': {'permissions.' + curr_user: {'$exists': True}}},\n",
    "            {'$skip': skip_amo},\n",
    "            {'$limit': limit_amo}]\n",
    "            #{'project': {ijaiosjdioasjd}}\n",
    "\n",
    "db = '2' \n",
    "    \n",
    "pipeline = [{'$lookup':\n",
    "                {'from' : '5', #Actors_db\n",
    "                 'localField' : '_id',\n",
    "                 'foreignField' : '_id',\n",
    "                 'as' : 'actor_dict'}},\n",
    "            {'$unwind': '$actor_dict'},\n",
    "           ]\n",
    "\n",
    "list(testDB['3'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex executions pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_first_result(first_stage_json):\n",
    "    newList = []\n",
    "    for actor in first_stage_json:\n",
    "        list_of_execution_info = []\n",
    "        aid = actor['_id']\n",
    "        newDict = {'_id': aid}\n",
    "        del actor['_id']\n",
    "        try:\n",
    "            del actor['permissions']\n",
    "        except:\n",
    "            pass\n",
    "        for key, value in actor.items():\n",
    "            list_of_execution_info.append(value)\n",
    "        newDict.update({'executions': list_of_execution_info})\n",
    "        newList.append(newDict)\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenant = 'DEV-DEVELOP'\n",
    "curr_user = 'testuser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = f'DEV-DEVELOP'\n",
    "pipeline = [{'$match': {'$text': {'$search': search}}},\n",
    "            {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "old_json = list(testDB['5'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executions\n",
    "# First Pipeline\n",
    "search = '\"DEV-DEVELOP_1952559\"'\n",
    "pipeline = [{'$match': {'$text': {'$search': search}}},\n",
    "            {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "old_json = list(testDB['3'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_input = converting_first_result(old_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDB['20'].drop()\n",
    "start = time.time()\n",
    "\n",
    "testDB['20'].insert_many(second_stage_input)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pipeline = [{'$match': {'executions.id': '8864362'}}]\n",
    "\n",
    "old_json = list(testDB['3'].aggregate(pipeline))\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executions\n",
    "# First Pipeline\n",
    "search = '\"DEV-DEVELOP_1952559\"'\n",
    "pipeline = [{'$match': {'$text': {'$search': search}}},\n",
    "            {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "old_json = list(testDB['3'].aggregate(pipeline))\n",
    "\n",
    "second_stage_input = converting_first_result(old_json)\n",
    "\n",
    "testDB['20'].drop()\n",
    "start = time.time()\n",
    "\n",
    "testDB['20'].insert_many(second_stage_input)\n",
    "print(time.time() - start)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "pipeline = [{'$match': {'executions.id': '8864362'}}]\n",
    "\n",
    "old_json = list(testDB['3'].aggregate(pipeline))\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a very large executions store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "actorsList = []\n",
    "for actors in range(2000):\n",
    "    aid = 'DEV-DEVELOP_' + str(random.randint(1000000, 9999999))\n",
    "    executionsList = []\n",
    "    for execs in range(random.randint(100, 2000)):\n",
    "        wid = random.randint(1000000, 9999999)\n",
    "        eid = random.randint(1000000, 9999999)\n",
    "        execDict = {'tenant': 'DEV-DEVELOP',\n",
    "                    'api_server': 'https://dev.tenants.develop.tacc.cloud',\n",
    "                    'actor_id': aid,\n",
    "                    'executor': 'testuser',\n",
    "                    'worker_id': wid,\n",
    "                    'id': eid,\n",
    "                    'message_received_time': '1585583279.07623',\n",
    "                    'start_time': '1585583279.400957',\n",
    "                    'runtime': 1,\n",
    "                    'cpu': 239084680,\n",
    "                    'io': 180,\n",
    "                    'status': 'COMPLETE',\n",
    "                    'exit_code': 0,\n",
    "                    'final_state': {'Status': 'exited',\n",
    "                                    'Running': False,\n",
    "                                    'Paused': False,\n",
    "                                    'Restarting': False,\n",
    "                                    'OOMKilled': False,\n",
    "                                    'Dead': False,\n",
    "                                    'Pid': 0,\n",
    "                                    'ExitCode': 0,\n",
    "                                    'Error': '',\n",
    "                                    'StartedAt': '2020-03-30T15:47:59.9001718Z',\n",
    "                                    'FinishedAt': '2020-03-30T15:48:00.654149Z'}}\n",
    "        executionsList.append(execDict)\n",
    "    actorsDict = {'_id': aid,\n",
    "                 'executions': executionsList}\n",
    "    actorsList.append(actorsDict)\n",
    "        \n",
    "expandedList = second_stage_input\n",
    "expandedList.extend(actorsList)\n",
    "testDB['3'].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fe12cb712c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDB['3'].insert_many(expandedList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example request\n",
    "#'?search=car&exactsearch=DEV-DEVELOP&search=dog&&skip=0&limit=10'\n",
    "\n",
    "# Mongo aggregation comparison expression operators to implement:\n",
    "# $eq, $gt, %gte, $lt, $lte, $ne, $in, $nin\n",
    "\n",
    "def get(search_type, args):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    # Given \n",
    "    tenant = 'DEV-DEVELOP'\n",
    "    curr_user = 'testuser'\n",
    "    \n",
    "    search_type = search_type.lower()\n",
    "    search, query, paging = arg_parser(args, tenant)\n",
    "    \n",
    "    # Executions and Workers store\n",
    "    if search_type in ['executions', 'workers']:\n",
    "        nested_search_pipeline(search_type, search, query, paging)\n",
    "    elif search_type in ['actors', 'logs']:\n",
    "        flat_search_pipeline(search_type, search, query, paging)\n",
    "    else:\n",
    "        raise KeyError(f'Inputted search_type is invalid, must be one of {list(store_dict.keys())}.')\n",
    "    \n",
    "\n",
    "def nested_search_pipeline(search_type, search, query, paging):\n",
    "    store_dict = {'executions': testDB['3'],\n",
    "                  'workers': testDB['6']}\n",
    "    queried_store = store_dict[search_type]\n",
    "        \n",
    "    # First pipeline setup and work\n",
    "    security = [{'$lookup':\n",
    "                    {'from' : '2',\n",
    "                     'localField' : '_id',\n",
    "                     'foreignField' : '_id',\n",
    "                     'as' : 'permissions'}},\n",
    "                {'$unwind': '$permissions'},\n",
    "                {'$match': {'permissions.' + curr_user: {'$exists': True}}}]\n",
    "    first_pipeline = search + security\n",
    "    first_res = list(queried_store.aggregate(pipeline))\n",
    "    print('-----PIPELINE-----\\n')\n",
    "    pprint.pprint(first_pipeline)\n",
    "    print('\\n\\n\\n-----RESULTANT-----')\n",
    "    pprint.pprint(first_res)\n",
    "\n",
    "    # Second pipeline setup and work\n",
    "    flat_first_res = mongo_flattener(first_res)\n",
    "    ## Should implement a call to use a random/unused database.\n",
    "    testDB['20'].drop()\n",
    "    testDB['20'].insert_many(flat_first_res)\n",
    "    testDB['20'].drop()\n",
    "    \n",
    "    # This should be implemented in arg_parser later\n",
    "    search = [{'$match': {'executions.id': '8864362'}}]\n",
    "    \n",
    "    second_pipeline = search + query + security + project + paging\n",
    "    second_res = list(queried_store.aggregate(pipeline))\n",
    "    print('-----PIPELINE-----\\n')\n",
    "    pprint.pprint(second_pipeline)\n",
    "    print('\\n\\n\\n-----RESULTANT-----')\n",
    "    pprint.pprint(second_res)\n",
    "\n",
    "    \n",
    "def arg_parser(args, tenant):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    query = []\n",
    "    search_terms = f\"{tenant}\"\n",
    "    skip_amo = None\n",
    "    limit_amo = None\n",
    "    \n",
    "    # Parsing args given by user, if multiple given, the arg comes as a list\n",
    "    for key, val in args.items():\n",
    "        # Adding search terms to 'search_terms'\n",
    "        if key == \"search\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = ' '.join(val)\n",
    "                search_terms = search_terms + f' {joined_val}'\n",
    "            else:\n",
    "                search_terms = search_terms + f' {val}'\n",
    "        # Adding exact search terms to 'search_terms', but now with double quotes\n",
    "        elif key == \"exactsearch\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = '\" \"'.join(val)\n",
    "                search_terms = search_terms + f' \"{joined_val}\"'\n",
    "            else:\n",
    "                search_terms = search_terms + f' \"{val}\"'\n",
    "        # Gets the number of results to skip\n",
    "        elif key == \"skip\":\n",
    "            if isinstance(val, list):\n",
    "                raise KeyError('Inputted \"skip\" paramater is invalid, parameter can only be specified once')\n",
    "            else:\n",
    "                skip_amo = int(val)\n",
    "        # Gets the number of results to show\n",
    "        elif key == \"limit\":\n",
    "            if isinstance(val, list):\n",
    "                raise KeyError('Inputted \"limit\" paramater is invalid, parameter can only be specified once')\n",
    "            else:\n",
    "                limit_amo = int(val)\n",
    "        else:\n",
    "            # Checking for logical operators and adds a pipeline match if found\n",
    "            used_oper = False\n",
    "            for oper in ['.$eq', '.$gt', '.$gte', '.$lt', '.$lte', '.$ne']:\n",
    "                if oper in key:\n",
    "                    key = key.split(oper)[0]\n",
    "                    oper = oper[1:]\n",
    "                    query += [{'$match': {key: {oper: val}}}]\n",
    "                    used_oper = True\n",
    "                    break\n",
    "            # If no local operators found then a regular pipeline match is used\n",
    "            if not used_oper:\n",
    "                query += [{'$match': {key: val}}]\n",
    "\n",
    "    ####### Check if search should start with tenant or not for speed. If so, delete this.\n",
    "    if search_terms:\n",
    "        search = [{'$match': {'$text': {'$search': search_terms}}},\n",
    "                  {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "    #pprint.pprint(search)\n",
    "    \n",
    "    paging = []\n",
    "    if skip_amo:\n",
    "        paging = paging + [{'$skip': skip_amo}]\n",
    "    if limit_amo:\n",
    "        paging = paging + [{'$limit': limit_amo}]\n",
    "    #pprint.pprint(paging)\n",
    "\n",
    "    return search, query, paging\n",
    "\n",
    "def mongo_flattener(mongo_input):\n",
    "    flatList = []\n",
    "    for actor in mongo_input:\n",
    "        list_of_execution_info = []\n",
    "        aid = actor['_id']\n",
    "        newDict = {'_id': aid}\n",
    "        del actor['_id']\n",
    "        \n",
    "        ################################################################DELETE THIS LATER\n",
    "        try:\n",
    "            del actor['permissions']\n",
    "        except:\n",
    "            pass\n",
    "        for _, value in actor.items():\n",
    "            list_of_execution_info.append(value)\n",
    "        newDict.update({'executions': list_of_execution_info})\n",
    "        flatList.append(newDict)\n",
    "    return flatList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
