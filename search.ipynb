{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import time\n",
    "import pymongo\n",
    "import json\n",
    "import pprint\n",
    "from pymongo.errors import WriteError, DuplicateKeyError\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import os\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "testDB = client.abaco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example request\n",
    "#'?search=car&exactsearch=DEV-DEVELOP&search=dog&&skip=0&limit=10'\n",
    "\n",
    "# Mongo aggregation comparison expression operators to implement:\n",
    "# $eq, $gt, %gte, $lt, $lte, $ne, $in, $nin\n",
    "\n",
    "def get(search_type, args):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    # Given \n",
    "    tenant = 'DEV-DEVELOP'\n",
    "    curr_user = 'testuser'\n",
    "    \n",
    "    search_type = search_type.lower()\n",
    "    search, query, paging = arg_parser(args, tenant)\n",
    "    \n",
    "    # Executions and Workers store\n",
    "    if search_type in ['executions', 'workers']:\n",
    "        nested_search_pipeline(search_type, search, query, paging)\n",
    "    elif search_type in ['actors', 'logs']:\n",
    "        flat_search_pipeline(search_type, search, query, paging)\n",
    "    else:\n",
    "        raise KeyError(f'Inputted search_type is invalid, must be one of {list(store_dict.keys())}.')\n",
    "    \n",
    "\n",
    "def nested_search_pipeline(search_type, search, query, paging):\n",
    "    store_dict = {'executions': testDB['3'],\n",
    "                  'workers': testDB['6']}\n",
    "    queried_store = store_dict[search_type]\n",
    "        \n",
    "    # First pipeline setup and work\n",
    "    security = [{'$lookup':\n",
    "                    {'from' : '2',\n",
    "                     'localField' : '_id',\n",
    "                     'foreignField' : '_id',\n",
    "                     'as' : 'permissions'}},\n",
    "                {'$unwind': '$permissions'},\n",
    "                {'$match': {'permissions.' + curr_user: {'$exists': True}}}]\n",
    "    first_pipeline = search + security\n",
    "    first_res = list(queried_store.aggregate(pipeline))\n",
    "    print('-----PIPELINE-----\\n')\n",
    "    pprint.pprint(first_pipeline)\n",
    "    print('\\n\\n\\n-----RESULTANT-----')\n",
    "    pprint.pprint(first_res)\n",
    "\n",
    "    # Second pipeline setup and work\n",
    "    flat_first_res = mongo_flattener(first_res)\n",
    "    ## Should implement a call to use a random/unused database.\n",
    "    testDB['20'].drop()\n",
    "    testDB['20'].insert_many(flat_first_res)\n",
    "    testDB['20'].drop()\n",
    "    \n",
    "    # This should be implemented in arg_parser later\n",
    "    search = [{'$match': {'executions.id': '8864362'}}]\n",
    "    \n",
    "    second_pipeline = search + query + security + project + paging\n",
    "    second_res = list(queried_store.aggregate(pipeline))\n",
    "    print('-----PIPELINE-----\\n')\n",
    "    pprint.pprint(second_pipeline)\n",
    "    print('\\n\\n\\n-----RESULTANT-----')\n",
    "    pprint.pprint(second_res)\n",
    "\n",
    "    \n",
    "def arg_parser(args, tenant):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    query = []\n",
    "    search_terms = f\"{tenant}\"\n",
    "    skip_amo = None\n",
    "    limit_amo = None\n",
    "    \n",
    "    # Parsing args given by user, if multiple given, the arg comes as a list\n",
    "    for key, val in args.items():\n",
    "        # Adding search terms to 'search_terms'\n",
    "        if key == \"search\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = ' '.join(val)\n",
    "                search_terms = search_terms + f' {joined_val}'\n",
    "            else:\n",
    "                search_terms = search_terms + f' {val}'\n",
    "        # Adding exact search terms to 'search_terms', but now with double quotes\n",
    "        elif key == \"exactsearch\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = '\" \"'.join(val)\n",
    "                search_terms = search_terms + f' \"{joined_val}\"'\n",
    "            else:\n",
    "                search_terms = search_terms + f' \"{val}\"'\n",
    "        # Gets the number of results to skip\n",
    "        elif key == \"skip\":\n",
    "            if isinstance(val, list):\n",
    "                raise KeyError('Inputted \"skip\" paramater is invalid, parameter can only be specified once')\n",
    "            else:\n",
    "                skip_amo = int(val)\n",
    "        # Gets the number of results to show\n",
    "        elif key == \"limit\":\n",
    "            if isinstance(val, list):\n",
    "                raise KeyError('Inputted \"limit\" paramater is invalid, parameter can only be specified once')\n",
    "            else:\n",
    "                limit_amo = int(val)\n",
    "        else:\n",
    "            # Checking for logical operators and adds a pipeline match if found\n",
    "            used_oper = False\n",
    "            for oper in ['.$eq', '.$gt', '.$gte', '.$lt', '.$lte', '.$ne']:\n",
    "                if oper in key:\n",
    "                    key = key.split(oper)[0]\n",
    "                    oper = oper[1:]\n",
    "                    query += [{'$match': {key: {oper: val}}}]\n",
    "                    used_oper = True\n",
    "                    break\n",
    "            # If no local operators found then a regular pipeline match is used\n",
    "            if not used_oper:\n",
    "                query += [{'$match': {key: val}}]\n",
    "\n",
    "    ####### Check if search should start with tenant or not for speed. If so, delete this.\n",
    "    if search_terms:\n",
    "        search = [{'$match': {'$text': {'$search': search_terms}}},\n",
    "                  {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "    #pprint.pprint(search)\n",
    "    \n",
    "    paging = []\n",
    "    if skip_amo:\n",
    "        paging = paging + [{'$skip': skip_amo}]\n",
    "    if limit_amo:\n",
    "        paging = paging + [{'$limit': limit_amo}]\n",
    "    #pprint.pprint(paging)\n",
    "\n",
    "    return search, query, paging\n",
    "\n",
    "def mongo_flattener(mongo_input):\n",
    "    flatList = []\n",
    "    for actor in mongo_input:\n",
    "        list_of_execution_info = []\n",
    "        aid = actor['_id']\n",
    "        newDict = {'_id': aid}\n",
    "        del actor['_id']\n",
    "        \n",
    "        ################################################################DELETE THIS LATER\n",
    "        try:\n",
    "            del actor['permissions']\n",
    "        except:\n",
    "            pass\n",
    "        for _, value in actor.items():\n",
    "            list_of_execution_info.append(value)\n",
    "        newDict.update({'executions': list_of_execution_info})\n",
    "        flatList.append(newDict)\n",
    "    return flatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----PIPELINE-----\n",
      "\n",
      "[{'$match': {'$text': {'$search': [{'$match': {'$text': {'$search': 'DEV-DEVELOP '\n",
      "                                                                    'DEV-DEVELOP'}}},\n",
      "                                   {'$sort': {'score': {'$meta': 'textScore'}}}]}}},\n",
      " {'$sort': {'score': {'$meta': 'textScore'}}},\n",
      " {'$lookup': {'as': 'permissions',\n",
      "              'foreignField': '_id',\n",
      "              'from': '2',\n",
      "              'localField': '_id'}},\n",
      " {'$unwind': '$permissions'},\n",
      " {'$match': {'permissions.testuser': {'$exists': True}}}]\n",
      "\n",
      "\n",
      "\n",
      "-----RESULTANT-----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a02bb355ce0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'executions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-bf4368f0ac06>\u001b[0m in \u001b[0;36mget\u001b[0;34m(search_type, args)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Executions and Workers store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msearch_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'executions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'workers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mnested_search_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msearch_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'actors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mflat_search_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaging\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-bf4368f0ac06>\u001b[0m in \u001b[0;36mnested_search_pipeline\u001b[0;34m(search_type, search, query, paging)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n\\n-----RESULTANT-----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Second pipeline setup and work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(object, stream, indent, width, depth, compact)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         compact=compact)\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0;32m--> 393\u001b[0;31m                                                 self._depth, level)\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pprint.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mrecursive\u001b[0m \u001b[0mconstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_safe_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pprint_default_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mrecursive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# '?search=7KEaNE8lrRw5k&search=KUBS&exactsearch=car&exactsearch=POPS&aid=FORDHmongENRY&aid.$gt=100010010'\n",
    "# args = {'search': ['7KEaNE8lrRw5k', 'KUBS'], 'exactsearch': ['car', 'POPS'], 'aid':'FORDHENRY', 'aid.$gt': '100010010'}\n",
    "\n",
    "# '?search=DEV-DEVELOP&aid=FORDHENRY&aid.$gt=100010010&skip=0&limit=10'\n",
    "# args = {'search': 'DEV-DEVELOP', 'aid':'FORDHENRY', 'aid.$gt': '100010010', 'skip':'0', 'limit':'10'}\n",
    "\n",
    "args = {'search': 'DEV-DEVELOP'}\n",
    "\n",
    "#args = {'search': 'DEV-DEVELOP_jJqjmq57Vjv55'}\n",
    "\n",
    "#args = {'exactsearch': ''}\n",
    "\n",
    "#args = {'search': 'DEV-DEVELOP', 'actor_id': 'DEV-DEVELOP_jJqjmq57Vjv55'}\n",
    "\n",
    "\n",
    "get('executions', args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$**_text'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do this to create a wildcard index on littttterally everything.\n",
    "testDB['3'].create_index([('$**', pymongo.TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(testDB[''].list_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = \"{tenant: DEV-DEVELOP}\"\n",
    "pipeline = [{'$match': {'tenant': tenant}},\n",
    "            {'$lookup':\n",
    "                {'from' : '2',\n",
    "                 'localField' : '_id',\n",
    "                 'foreignField' : '_id',\n",
    "                 'as' : 'permissions'}},\n",
    "            {'$unwind': '$permissions'},\n",
    "            {'$match': {'permissions.' + curr_user: {'$exists': True}}}]\n",
    "\n",
    "list(testDB['3'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex. Update logs fields if actors exists\n",
    "pipeline = [{'$match': {'$text': {'$search': search}}},\n",
    "            {'$sort': {'score': {'$meta': 'textScore'}}},\n",
    "            {'$match': {'tenant': tenant}},\n",
    "            {'$lookup':\n",
    "                {'from' : '2',\n",
    "                 'localField' : 'actor_id',\n",
    "                 'foreignField' : '_ifd',\n",
    "                 'as' : 'permissions'}},\n",
    "            {'$unwind': '$permissions'},\n",
    "            {'$match': {'permissions.' + curr_user: {'$exists': True}}},\n",
    "            {'$skip': skip_amo},\n",
    "            {'$limit': limit_amo}]\n",
    "            #{'project': {ijaiosjdioasjd}}\n",
    "\n",
    "db = '2' \n",
    "    \n",
    "pipeline = [{'$lookup':\n",
    "                {'from' : '5', #Actors_db\n",
    "                 'localField' : '_id',\n",
    "                 'foreignField' : '_id',\n",
    "                 'as' : 'actor_dict'}},\n",
    "            {'$unwind': '$actor_dict'},\n",
    "           ]\n",
    "\n",
    "list(testDB['3'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex executions pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_first_result(first_stage_json):\n",
    "    newList = []\n",
    "    for actor in first_stage_json:\n",
    "        list_of_execution_info = []\n",
    "        aid = actor['_id']\n",
    "        newDict = {'_id': aid}\n",
    "        del actor['_id']\n",
    "        try:\n",
    "            del actor['permissions']\n",
    "        except:\n",
    "            pass\n",
    "        for key, value in actor.items():\n",
    "            list_of_execution_info.append(value)\n",
    "        newDict.update({'executions': list_of_execution_info})\n",
    "        newList.append(newDict)\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenant = 'DEV-DEVELOP'\n",
    "curr_user = 'testuser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = f'DEV-DEVELOP'\n",
    "pipeline = [{'$match': {'$text': {'$search': search}}},\n",
    "            {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "old_json = list(testDB['5'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executions\n",
    "# First Pipeline\n",
    "search = '\"DEV-DEVELOP_1952559\"'\n",
    "pipeline = [{'$match': {'$text': {'$search': search}}},\n",
    "            {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "old_json = list(testDB['3'].aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_input = converting_first_result(old_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDB['20'].drop()\n",
    "start = time.time()\n",
    "\n",
    "testDB['20'].insert_many(second_stage_input)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "pipeline = [{'$match': {'executions.id': '8864362'}}]\n",
    "\n",
    "old_json = list(testDB['3'].aggregate(pipeline))\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executions\n",
    "# First Pipeline\n",
    "search = '\"DEV-DEVELOP_1952559\"'\n",
    "pipeline = [{'$match': {'$text': {'$search': search}}},\n",
    "            {'$sort': {'score': {'$meta': 'textScore'}}}]\n",
    "old_json = list(testDB['3'].aggregate(pipeline))\n",
    "\n",
    "second_stage_input = converting_first_result(old_json)\n",
    "\n",
    "testDB['20'].drop()\n",
    "start = time.time()\n",
    "\n",
    "testDB['20'].insert_many(second_stage_input)\n",
    "print(time.time() - start)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "pipeline = [{'$match': {'executions.id': '8864362'}}]\n",
    "\n",
    "old_json = list(testDB['3'].aggregate(pipeline))\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a very large executions store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "actorsList = []\n",
    "for actors in range(2000):\n",
    "    aid = 'DEV-DEVELOP_' + str(random.randint(1000000, 9999999))\n",
    "    executionsList = []\n",
    "    for execs in range(random.randint(100, 2000)):\n",
    "        wid = random.randint(1000000, 9999999)\n",
    "        eid = random.randint(1000000, 9999999)\n",
    "        execDict = {'tenant': 'DEV-DEVELOP',\n",
    "                    'api_server': 'https://dev.tenants.develop.tacc.cloud',\n",
    "                    'actor_id': aid,\n",
    "                    'executor': 'testuser',\n",
    "                    'worker_id': wid,\n",
    "                    'id': eid,\n",
    "                    'message_received_time': '1585583279.07623',\n",
    "                    'start_time': '1585583279.400957',\n",
    "                    'runtime': 1,\n",
    "                    'cpu': 239084680,\n",
    "                    'io': 180,\n",
    "                    'status': 'COMPLETE',\n",
    "                    'exit_code': 0,\n",
    "                    'final_state': {'Status': 'exited',\n",
    "                                    'Running': False,\n",
    "                                    'Paused': False,\n",
    "                                    'Restarting': False,\n",
    "                                    'OOMKilled': False,\n",
    "                                    'Dead': False,\n",
    "                                    'Pid': 0,\n",
    "                                    'ExitCode': 0,\n",
    "                                    'Error': '',\n",
    "                                    'StartedAt': '2020-03-30T15:47:59.9001718Z',\n",
    "                                    'FinishedAt': '2020-03-30T15:48:00.654149Z'}}\n",
    "        executionsList.append(execDict)\n",
    "    actorsDict = {'_id': aid,\n",
    "                 'executions': executionsList}\n",
    "    actorsList.append(actorsDict)\n",
    "        \n",
    "expandedList = second_stage_input\n",
    "expandedList.extend(actorsList)\n",
    "testDB['3'].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fe12cb712c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDB['3'].insert_many(expandedList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example request\n",
    "#'?search=car&exactsearch=DEV-DEVELOP&search=dog&&skip=0&limit=10'\n",
    "\n",
    "# Mongo aggregation comparison expression operators to implement:\n",
    "# $eq, $gt, %gte, $lt, $lte, $ne, $in, $nin\n",
    "\n",
    "def get(search_type, args):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    #args = dict(args.lists())    \n",
    "    \n",
    "    search_type = search_type.lower()\n",
    "    search, query, paging = arg_parser(args)\n",
    "    \n",
    "    # Executions and Workers store\n",
    "    if search_type == 'executions' or search_type =='workers':\n",
    "        nested_search_pipeline(search, query, paging)\n",
    "    elif search_type == 'actors' or search_type == 'logs':\n",
    "        flat_search_pipeline(search, query, paging)\n",
    "    else:\n",
    "        raise KeyError(f'Inputted search_type is invalid, must be one of {list(store_dict.keys())}.')\n",
    "    \n",
    "\n",
    "def nested_search_pipeline(search, query, paging):\n",
    "    print('-----PIPELINE-----\\n')\n",
    "    pprint.pprint(pipeline)\n",
    "    print('\\n\\n\\n-----RESULTANT-----')\n",
    "    pprint.pprint(list(queried_store.aggregate(pipeline)))    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def get_derived_query_sections(search_type):\n",
    "    queried_store, security, project = get_derived_pipeline_sections(search_type)\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    store_dict = {'executions': testDB['3'],\n",
    "                  'workers': testDB['6'],\n",
    "                  'actors': testDB['5'],\n",
    "                  'logs': testDB['1']}\n",
    "    try:\n",
    "        queried_store = store_dict[search_type]\n",
    "    except KeyError:\n",
    "        raise KeyError(f'Inputted search_type is invalid, must be one of {list(store_dict.keys())}.')\n",
    "    \n",
    "    if search_type == 'executions':\n",
    "        security = [{'$match': {'tenant': tenant}},\n",
    "                    {'$lookup':\n",
    "                        {'from' : '2',\n",
    "                         'localField' : 'actor_id',\n",
    "                         'foreignField' : '_id',\n",
    "                         'as' : 'permissions'}},\n",
    "                    {'$unwind': '$permissions'},\n",
    "                    {'$match': {'permissions.' + curr_user: {'$exists': True}}}]\n",
    "        project = [{'project': {'ijaiosjdioasjd'}}]\n",
    "        \n",
    "    elif search_type == 'workers':\n",
    "        security = [{'$match': {'tenant': tenant}},\n",
    "                    {'$lookup':\n",
    "                        {'from' : '2',\n",
    "                         'localField' : 'actor_id',\n",
    "                         'foreignField' : '_id',\n",
    "                         'as' : 'permissions'}},\n",
    "                    {'$unwind': '$permissions'},\n",
    "                    {'$match': {'permissions.' + curr_user: {'$exists': True}}}]\n",
    "        project = [{'project': {'ijaiosjdioasjd'}}]\n",
    "        \n",
    "    elif search_type == 'actors':\n",
    "        security = [{'$match': {'tenant': tenant}},\n",
    "                    {'$lookup':\n",
    "                        {'from' : '2',\n",
    "                         'localField' : 'actor_id',\n",
    "                         'foreignField' : '_id',\n",
    "                         'as' : 'permissions'}},\n",
    "                    {'$unwind': '$permissions'},\n",
    "                    {'$match': {'permissions.' + curr_user: {'$exists': True}}}]\n",
    "        project = [{'project': {'ijaiosjdioasjd'}}]\n",
    "        \n",
    "    elif search_type == 'logs':\n",
    "        #Good\n",
    "        security = [{'$match': {'tenant': tenant}},\n",
    "                {'$lookup':\n",
    "                    {'from' : '2',\n",
    "                     'localField' : 'actor_id',\n",
    "                     'foreignField' : '_id',\n",
    "                     'as' : 'permissions'}},\n",
    "                {'$unwind': '$permissions'},\n",
    "                {'$match': {'permissions.' + curr_user: {'$exists': True}}}]\n",
    "        project = [{'project': {'ijaiosjdioasjd'}}]\n",
    "        \n",
    "    return queried_store, security, project\n",
    "\n",
    "def arg_parser(args):\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    query = []\n",
    "    search = \"\"\n",
    "    skip_amo = None\n",
    "    limit_amo = None\n",
    "    \n",
    "    for key, val in args.items():\n",
    "        if key == \"search\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = ' '.join(val)\n",
    "                search = search + f' {joined_val}'\n",
    "            else:\n",
    "                search = search + f' {val}'\n",
    "        elif key == \"exactsearch\":\n",
    "            if isinstance(val, list):\n",
    "                joined_val = '\" \"'.join(val)\n",
    "                search = search + f' \"{joined_val}\"'\n",
    "            else:\n",
    "                search = search + f' \"{val}\"'\n",
    "        elif key == \"skip\":\n",
    "            if isinstance(val, list):\n",
    "                raise KeyError('Inputted \"skip\" paramater is invalid, parameter can only be specified once')\n",
    "            else:\n",
    "                skip_amo = int(val)\n",
    "        elif key == \"limit\":\n",
    "            if isinstance(val, list):\n",
    "                raise KeyError('Inputted \"limit\" paramater is invalid, parameter can only be specified once')\n",
    "            else:\n",
    "                limit_amo = int(val)\n",
    "        else:\n",
    "            used_oper = False\n",
    "            for oper in ['.$eq', '.$gt', '.$gte', '.$lt', '.$lte', '.$ne']:\n",
    "                if oper in key:\n",
    "                    key = key.split(oper)[0]\n",
    "                    oper = oper[1:]\n",
    "                    query += [{'$match': {key: {oper: val}}}]\n",
    "                    used_oper = True\n",
    "                    break\n",
    "            if not used_oper:\n",
    "                query += [{'$match': {key: val}}]\n",
    "\n",
    "    if search:\n",
    "        search = search[1:] # getting rid of initial space\n",
    "        query = [{'$match': {'$text': {'$search': search}}},\n",
    "                 {'$sort': {'score': {'$meta': 'textScore'}}}] + query\n",
    "    #pprint.pprint(query)\n",
    "    \n",
    "    paging = []\n",
    "    if skip_amo:\n",
    "        paging = paging + [{'$skip': skip_amo}]\n",
    "    if limit_amo:\n",
    "        paging = paging + [{'$limit': limit_amo}]\n",
    "    #pprint.pprint(paging)\n",
    "\n",
    "    return query, paging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
