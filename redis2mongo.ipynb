{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import redis\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://localhost:27015')\n",
    "db = client.abaco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mongo Conversion\n",
    "# Helper functions that converts Mongo to new formatting\n",
    "def updateMongoLogs(old_json, executions):\n",
    "    newList = []\n",
    "    for actor in old_json:\n",
    "        aid = actor['_id']\n",
    "        newDict = {'exp': actor['exp'], '_id': aid, 'logs': actor[aid]}\n",
    "        newList.append(newDict)\n",
    "        \n",
    "    for log in newList:\n",
    "        wanted_exec_id = log['_id']\n",
    "        for execution in executions:\n",
    "            for exec_id, exec_info in execution.items():\n",
    "                if exec_id == '_id':\n",
    "                    continue\n",
    "                if exec_id == wanted_exec_id:\n",
    "                    log['actor_id'] = execution['_id']\n",
    "                    log['tenant'] = exec_info['tenant']\n",
    "                    break\n",
    "    return newList\n",
    "\n",
    "def updateMongoPermissions(old_json):\n",
    "    newList = []\n",
    "    for actor in old_json:\n",
    "        aid = actor['_id']\n",
    "        newDict = {'_id': aid}\n",
    "        newDict.update(actor[aid])\n",
    "        newList.append(newDict)\n",
    "    return newList\n",
    "\n",
    "def updateMongoExecutions(old_json):\n",
    "    newList = []\n",
    "    for actor in old_json:\n",
    "        aid = actor['_id']\n",
    "        newDict = {'_id': aid}\n",
    "        newDict.update(actor[aid])\n",
    "        newList.append(newDict)\n",
    "    return newList\n",
    "\n",
    "def updateMongoClients(old_json):\n",
    "    newList = []\n",
    "    for actor in old_json:\n",
    "        aid = actor['_id']\n",
    "        newDict = {'_id': aid}\n",
    "        newDict.update(actor[aid])\n",
    "        newList.append(newDict)\n",
    "    return newList\n",
    "\n",
    "# Redis Conversion\n",
    "# Helper function that converts a Redis DB into a JSON dict\n",
    "def redis2dict(db):\n",
    "    allDocs = []\n",
    "    redisDB = redis.Redis(db=db, port=6397)\n",
    "    for key in redisDB.scan_iter():\n",
    "        key = key.decode('utf-8')\n",
    "        jsonDict = json.loads(redisDB.get(key))\n",
    "        jsonDict['_id'] = key\n",
    "        allDocs.append(jsonDict)\n",
    "    return allDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_logs_store_json = list(db['1'].find({}))\n",
    "old_permissions_store_json = list(db['2'].find({}))\n",
    "old_executions_store_json = list(db['3'].find({}))\n",
    "old_clients_store_json = list(db['4'].find({}))\n",
    "old_actors_store_json = redis2dict('1')\n",
    "old_workers_store_json = redis2dict('2')\n",
    "old_nonce_store_json = redis2dict('3')\n",
    "old_alias_store_json = redis2dict('4')\n",
    "old_pregen_clients_json = redis2dict('5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_permissions = updateMongoPermissions(old_permissions_store_json)\n",
    "converted_executions = updateMongoExecutions(old_executions_store_json)\n",
    "converted_clients = updateMongoClients(old_clients_store_json)\n",
    "converted_actors = old_actors_store_json\n",
    "converted_workers = old_workers_store_json\n",
    "converted_nonces = old_nonce_store_json\n",
    "converted_aliases = old_alias_store_json\n",
    "converted_pregen = old_pregen_clients_json\n",
    "converted_logs = updateMongoLogs(old_logs_store_json, converted_executions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_naming = {'n1': converted_logs,\n",
    "             'n2': converted_permissions,\n",
    "             'n3': converted_executions,\n",
    "             'n4': converted_clients,\n",
    "             'n5': converted_actors,\n",
    "             'n6': converted_workers,\n",
    "             'n7': converted_nonces,\n",
    "             'n8': converted_aliases,\n",
    "             'n9': converted_pregen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing db: n1\n",
      "Currently processing db: n2\n",
      "Currently processing db: n3\n",
      "Currently processing db: n4\n",
      "Currently processing db: n5\n",
      "Currently processing db: n6\n",
      "Currently processing db: n7\n",
      "Currently processing db: n8\n",
      "Currently processing db: n9\n"
     ]
    }
   ],
   "source": [
    "# Convert and upload modified data\n",
    "for db_name, db_data in db_naming.items(): \n",
    "    try:\n",
    "        print(f\"Currently processing db: {db_name}\")\n",
    "        db[db_name].drop()\n",
    "        db[db_name].insert_many(db_data)\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Stuff Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issueRaise(new, old, words):\n",
    "    print(f\"Issue - {words}\")\n",
    "    pprint(new)\n",
    "    print(\"=======================================\")\n",
    "    pprint(old)\n",
    "    raise ValueError(words)\n",
    "\n",
    "def increment(store, key):\n",
    "    if key in store:\n",
    "        store[key] += 1\n",
    "    else:\n",
    "        store[key] = 1\n",
    "\n",
    "def incrementVals(store, key, val):\n",
    "    if key in store:\n",
    "        store[key].append(val)\n",
    "    else:\n",
    "        store[key] = [val]\n",
    "        \n",
    "def lenAndValCheck(inpDict):\n",
    "    try:  \n",
    "        keyStore = {}\n",
    "        valStore = {}\n",
    "        for i, actor in enumerate(inpDict):\n",
    "                for worker in actor:\n",
    "                    if worker == '_id':\n",
    "                        increment(keyStore, '#actor_ids')\n",
    "                        incrementVals(valStore, '#actor_ids', actor['_id'])\n",
    "                    else:\n",
    "                        for key, val in actor[worker].items():\n",
    "                            increment(keyStore, key)\n",
    "                            incrementVals(valStore, key, val)\n",
    "    except AttributeError:\n",
    "        keyStore = {}\n",
    "        valStore = {}\n",
    "        for i, actor in enumerate(inpDict):\n",
    "                for key, val in actor.items():\n",
    "                    increment(keyStore, key)\n",
    "                    incrementVals(valStore, key, val)\n",
    "    return keyStore, valStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Convert old_coll to new stylings and use that as input.\n",
    "def conversionChecker(new, old, debug=False):\n",
    "    newKeys, newVals = lenAndValCheck(new)\n",
    "    oldKeys, oldVals = lenAndValCheck(old)\n",
    "    if debug:\n",
    "        print(f'New Keys:\\n{newKeys}\\n Old Keys:\\n{oldKeys}')\n",
    "    for key in newKeys:\n",
    "        try:\n",
    "            if not newKeys[key] == oldKeys[key]:\n",
    "                issueRaise(newVals[key], oldVals[key], f\"Value lengths are not the same. {newKeys[key]} and {oldKeys[key]}.\")\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Key: {key} not found in old JSON.\")\n",
    "    for key in oldKeys:\n",
    "        try:\n",
    "            if not newKeys[key] == oldKeys[key]:\n",
    "                issueRaise(newVals[key], oldVals[key], f\"Value lengths are not the same. {newKeys[key]} and {oldKeys[key]}.\")\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Key: '{key}' not found in new JSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logs_store_json = list(db['1'].find({}))\n",
    "new_permissions_store_json = list(db['2'].find({}))\n",
    "new_executions_store_json = list(db['3'].find({}))\n",
    "new_clients_store_json = list(db['4'].find({}))\n",
    "new_actors_store_json = list(db['5'].find({}))\n",
    "new_workers_store_json = list(db['6'].find({}))\n",
    "new_nonce_store_json = list(db['7'].find({}))\n",
    "new_alias_store_json = list(db['8'].find({}))\n",
    "new_pregen_clients_json = list(db['9'].find({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get JSON for each Redis store\n",
    "old_logs_store_json = list(db['1'].find({}))\n",
    "old_permissions_store_json = list(db['2'].find({}))\n",
    "old_executions_store_json = list(db['3'].find({}))\n",
    "old_clients_store_json = list(db['4'].find({}))\n",
    "old_actors_store_json = redis2dict('1')\n",
    "old_workers_store_json = redis2dict('2')\n",
    "old_nonce_store_json = redis2dict('3')\n",
    "old_alias_store_json = redis2dict('4')\n",
    "old_pregen_clients_json = redis2dict('5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key: 'exp' not found in new JSON.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1789b2b0e0ad>\u001b[0m in \u001b[0;36mconversionChecker\u001b[0;34m(new, old, debug)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnewKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moldKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0missueRaise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewVals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moldVals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Value lengths are not the same. {newKeys[key]} and {oldKeys[key]}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'exp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-4f0c3587bb5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconversionChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_logs_store_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdateMongoLogs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_logs_store_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-1789b2b0e0ad>\u001b[0m in \u001b[0;36mconversionChecker\u001b[0;34m(new, old, debug)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0missueRaise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewVals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moldVals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Value lengths are not the same. {newKeys[key]} and {oldKeys[key]}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key: '{key}' not found in new JSON.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: \"Key: 'exp' not found in new JSON.\""
     ]
    }
   ],
   "source": [
    "conversionChecker(new_logs_store_json, updateMongoLogs(old_logs_store_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversionChecker(new_permissions_store_json, updateMongoPermissions(old_permissions_store_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversionChecker(new_executions_store_json, updateMongoExecutions(old_executions_store_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversionChecker(new_actors_store_json, old_actors_store_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversionChecker(new_workers_store_json, old_workers_store_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversionChecker(new_nonce_store_json, old_nonce_store_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversionChecker(new_alias_store_json, old_alias_store_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversionChecker(new_pregen_clients_json, old_pregen_clients_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Convert old_coll to new stylings and use that as input.\n",
    "def conversionChecker(new, old):\n",
    "    if not type(new) == type(old):\n",
    "        issueRaise(new, old, \"Types aren't the same.\")\n",
    "    if isinstance(new, list) and isinstance(old, list):\n",
    "        if not len(new) == len(old):\n",
    "            issueRaise(new, old, \"Lists aren't the same length.\")\n",
    "        for new_iter, old_iter in zip(new, old):\n",
    "            conversionChecker(new_iter, old_iter)\n",
    "    elif isinstance(new, dict) and isinstance(old, dict):\n",
    "        if not len(new) == len(old):\n",
    "            issueRaise(new, old, \"Dict's aren't the same length.\")\n",
    "        if not new.keys() == old.keys():\n",
    "            for new_key, old_key in zip(new.keys(), old.keys()):\n",
    "                if not new_key == old_key:\n",
    "                    if not len(new_key) == len(old_key):\n",
    "                        issueRaise(new_key, old_key, \"Dict's keys aren't the same.\")\n",
    "\n",
    "        for new_key, old_key in zip(new.keys(), old.keys()):\n",
    "            if new_key in ['_id', 'exp', 'start_time', 'io', 'runtime', 'cpu', 'FinishedAt', 'StartedAt',\n",
    "                           'create_time', 'last_update_time', 'message_received_time']:\n",
    "                pass\n",
    "            elif new_key in ['actor_id', 'logs', 'id', 'worker_id', 'db_id']:\n",
    "                if not len(new[new_key]) == len(old[old_key]):\n",
    "                    issueRaise(new_key, old_key, f\"Dict's keys aren't the same. {new[new_key]} | {old[old_key]}\")\n",
    "            else:\n",
    "                conversionChecker(new[new_key], old[old_key])\n",
    "\n",
    "    else:\n",
    "        if not new == old:\n",
    "            issueRaise(new, old, \"Items aren't the same.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
